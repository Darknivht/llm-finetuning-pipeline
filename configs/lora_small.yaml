training:
  model_name_or_path: "distilgpt2"
  output_dir: "./checkpoints/lora_small"
  num_train_epochs: 3
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 8
  learning_rate: 2e-4
  warmup_steps: 100
  logging_steps: 50
  save_steps: 500
  eval_steps: 500
  max_seq_length: 512
  use_peft: true
  lora_rank: 16
  lora_alpha: 32
  lora_dropout: 0.1
  device: "auto"
  fp16: true
  seed: 42

data:
  data_path: "./data"
  text_column: "text"
  label_column: "label"
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  max_examples: null
  cache_dir: "./data/cache"

eval:
  batch_size: 8
  max_new_tokens: 50
  temperature: 0.7
  top_k: 50
  top_p: 0.9
  num_beams: 1
  do_sample: true
  compute_metrics: true

api:
  openai_api_key: null
  openrouter_base_url: "https://openrouter.ai/api/v1"
  openrouter_model: "openrouter/auto"
  use_openrouter_fallback: true
  max_retries: 3
  timeout: 30